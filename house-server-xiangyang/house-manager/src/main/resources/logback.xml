<?xml version="1.0" encoding="UTF-8" ?>
<configuration scan="true">
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>

    <appender name="eventFile" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/logFile.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>logs/%d{yyyy-MM-dd}.log</fileNamePattern>
            <maxHistory>30</maxHistory>
        </rollingPolicy>
<!--        当文件超过5MB时，生成新文件-->
<!--        <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">            　　　　　　　　　　-->
<!--            <maxFileSize>5MB</maxFileSize>            　　　　　　-->
<!--        </triggeringPolicy>-->
        <encoder>
            <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>

<!--    <appender name="kafkaAppender" class="com.github.danielwegener.logback.kafka.KafkaAppender">-->
<!--        <encoder>-->
<!--            <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>-->
<!--        </encoder>-->
<!--        <topic>kafka-log4j</topic>-->
<!--        <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy"/>-->
<!--        <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy"/>-->
<!--        <producerConfig>bootstrap.servers=192.168.2.130:9092</producerConfig>-->
<!--    </appender>-->

    <root level="INFO">
        <appender-ref ref="STDOUT"/>
<!--        <appender-ref ref="kafkaAppender"/>-->
        <appender-ref ref="eventFile"/>
    </root>
</configuration>